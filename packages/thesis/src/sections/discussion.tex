\section{Discussion}
\label{sec:discussion}
Looking back at the results of the experiments, we can see that all feature sets are able to reduce the overall damage of the infrastructure. Where the local-agent is able to reduce only a small amount of damage, the auctioning and knowledge-sharing agents are able to reduce the damage significantly and in a shorter amount of time. 

% \add{Mention the amount of risks detected}
\subsection{Risks Detected}
\label{ssec:risks-detected}
From the figures detailing the unique number of risks detected (figures \ref{fig:risk-count-no-change}, \ref{fig:risk-count-risk-introduction}, \ref{fig:risk-count-growing}, and \ref{fig:risk-count-unstable}) we can see that the local-agent is only able to detect a fraction of the risks that the auctioning and knowledge-sharing agents are able to detect. This is expected as the local-agent cannot share any information with its neighbors, and therefore cannot detect any risks that have an origin outside of its own infrastructure node and software component.

The auctioning agents are able to detect more risks than the knowledge-sharing agents, up to $200\%$ in figure \ref{fig:risk-count-no-change}. 

When comparing the unique number of risks detected to the number of remaining risks in the infrastructure (figures \ref{fig:risk-remaining-no-change}, \ref{fig:risk-remaining-risk-introduction}, \ref{fig:risk-remaining-growing}, \ref{fig:risk-remaining-unstable}) we can see that for the first scenario the auctioning agent detects $150$ out of $600$ risks, which is $25\%$ of the total amount of risks. The knowledge-sharing agent detects $50$ out of $600$ risks, which is $8.3\%$ of the total amount of risks. 

As mentioned before, in the ADRIAN-concept by Mann and Smolka \cite{mann2023ADRIAN} the distance a message can travel is detailed. We believe that the agents would be able to detect more risks if this distance was increased. However, metrics that are collected are not enough to conclude this fully. In the next section (Section \ref{sec:future-research}) this will be discussed further.

% \add{Explain why knowledge-sharing damage output is sometimes better, but more time adaptating is bad}
\subsection{Damage Reduction \& Adaptation Time}
\label{ssec:damage-reduction}
In the results we see that overall knowledge-sharing and auctioning agents tend to perform similarly when looking at the overall damage of the infrastructure. However, when we look at the time spent adapting, we can see that in all cases the knowledge-sharing agents spend almost twice as much time applying adaptations.
Depending on the adaptation, this could mean that the software components running on the infrastructure node could become unavailable for longer periods of time, and that the infrastructure node is unresponsive while applying the adaptations.  In the last scenario (figure \ref{fig:adapting-time-unstable}) we see that the knowledge-sharing agents spends $30$ seconds of the $180$ seconds it was running, which is $16.7\%$ of the time it was running. 

In a real-world scenario this downtime would likely be unfavorable, but should be weighed against the damage that could be done when not applying any adaptations. Applying many adaptations early on could prevent any damage later on, which could be more important than the downtime.


% \add{Mention that adaptation count is the same, but time spent adapting is different}
\subsection{Efficient Adaptations}
\label{ssec:efficient-adaptations}
When looking at the number of adaptations that are applied (figures \ref{fig:proposals-no-change}, \ref{fig:proposals-risk-introduction}, \ref{fig:proposals-growing}, and \ref{fig:proposals-unstable}) we can see that the auctioning and knowledge-sharing agents perform similarly. However, when looking at the time spent adapting (figures \ref{fig:adapting-time-no-change}, \ref{fig:adapting-time-risk-introduction}, \ref{fig:adapting-time-growing}, and \ref{fig:adapting-time-unstable}) we can see that the knowledge-sharing agents spend almost twice as much time adapting. This is an indicator that the auctioning agents are able to apply more efficient adaptations, as they are able to apply the same amount of adaptations in a shorter amount of time, while also reducing the overall damage roughly the same amount.

% \add{Mention the stability of the system}
\subsection{Stability}
\label{ssec:stability}
As the scenarios run their course, we can see that the knowledge-sharing and auctioning agents are able to keep the damage of the infrastructure at a low level. Especially in the Growing Infrastructure scenario (figure \ref{fig:overall-damage-growing-infrastructure}) we see that the damage is kept at a low level, even though the infrastructure is growing. 

The auctioning-agent is able to keep the damage at $10.78\%$ of the damage compared to the local-agent. While the knowledge-sharing agent is able stay at $21.99\%$ of the damage. This is a good result, as the infrastructure is growing, and the agents are able to keep the damage at a low level.

\paragraph*{Small Infrastructure}
During the implementation of the system we noticed that the performance of the different feature-sets was slightly different when the infrastructure was small. The knowledge-sharing agents tends to reach the lowest points almost $50\%$ faster than the auctioning-agent. We believe this to be because of the overhead that is introduced by auctioning. Figure \ref{fig:small-infra-no-change} shows the performance of the different feature-sets in the no-change scenario with a small infrastructure consisting of four infrastructure nodes and two software components.

\begin{figure}[H]
    \centering
        \input{graphs/small-infra-no-change}
    \caption{Graph showing the output of all feature sets in the non-changing scenario, with a small infrastructure.}
    \label{fig:small-infra-no-change}
\end{figure}

After carefully inspecting the logs, two likely causes are identified. Instead of applying the adaptations directly, the agents first have to auction the adaptations. And after this time only one is allowed to apply the adaptation. This while the knowledge-sharing agents can apply these found adaptations directly. 

Additionally, because of the infrastructure size there is only a limited amount of risks, the changes of finding a better adaptation via an auction is smaller in that case. Both of these factors are likely to cause this difference in performance, but further research would be needed to confirm this.

\subsection{Large Infrastructure}
\begin{figure}[H]
    \centering
        \input{graphs/large-infra-large}
    \caption{Graph showing the output of all feature sets in the non-changing scenario, with a large infrastructure.}
    \label{fig:large-infra-large}
\end{figure}

% \add{Mention the spread in consecutive runs}
% \add{Mention the performance of knowledge-sharing in smaller networks}

\subsection{Consistency}
\label{ssec:consecutive-runs}
During some of the experiments we see a small fluctuation in the behavior of agents. One good example of this is figure \ref{fig:adapting-time-no-change} compared to \ref{fig:adapting-time-risk-introduction}. We believe this is because of the scheduling of threads by the OS. This could lead into different auctions being initiated and joined over multiple runs. 

To test this assumption, we ran the no-change scenario with the auctioning feature-set $5$ times. The results of this can be seen in figure \ref{fig:multi-run-no-change}. We see that the overall damage is very similar in all runs. However, small differences can be observed across the runs.

\begin{figure}[H]
    \centering
        \input{graphs/multi-run-no-change}
    \caption{Graph showing the Auctioning Feature's performance over multiple runs in the no-change scenario.}
    \label{fig:multi-run-no-change}
\end{figure}

The metrics that are collected are not enough to fully pin-point this behavior to scheduling. but, the results seem to indicate that the variety in the performance of the agents is small, and no further investigation has been performed. However, The result from figure \ref{fig:multi-run-no-change} are positive, as it means that the agents are able to perform consistently over multiple runs.

