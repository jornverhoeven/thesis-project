\section{Problem Analysis}
\label{sec:problem-analysis}

% Things to mention:
% - Nodes, Agents, Software Components, Links, Critical Software.
% - Attack Graphs, Risk Rules, Risk Probability.
% - Auctioning, Attack Graph Merging, Mitigation Proposals, Ranking of Mitigation strategies.

% \add{Talk about hardware requirements and the compute power available for IoT devices}
% \add{Talk about a Graph based approach and how it could help solve the hardware requirement issue}
% \add{Talk about using CVE\'s}
% \add{Talk about Mitigation Strategies and possible adaptation patterns}

As mentioned in Section \ref{sec:project-summary} it is not yet clear what the best solution would be to detect security risks in a network when looking at IoT devices \cite{zarpelao2017survey}. Many researchers have looked into this topic, but none have looked into the approach proposed by Z.A. Mann and S. Smolke proposed with ADRIAN; A graph of decentralized agents working together to identify risks and propose mitigations to a network, in order to optimise (reduce) the overall risk of said network.

The proposed ADRIAN protocol is an abstract concept which can be applied to any network of connected devices; for example a network of IoT devices, a set of servers, or a hybrid configuration. The concept uses terminology as \emph{Nodes} and \emph{Links}, instead of terms such as \emph{Device} and \emph{Connection}, to abstract away the specific domains. It should therefore be noted that as the domain of IoT devices is used as an anchor for this research, theoretically it should also be usable for other networks such as larger networks of servers. 

The problem with doing risk assessment on IoT devices is that the hardware for the chips is usually very limited, such as commonly used ARM chips \cite{singh2020overview}. As most devices like smart sensors are very tiny, they usually are not shipped with too much computing power. This limits their capability of performing extensive calculations and makes the tasks different from networks that run full-fetched servers with many CPUs and RAM available.

Secondly, the task of identifying risks is more difficult because some proposed strategies look at network packets which might not always be (fully) available \cite{canedo2016using, hamza2019detecting, sivanathan2018classifying}.

The proposed method uses a graph-based approach similar to Paudel et al. \cite{paudel2019detecting}. ADRIAN envisions software agents running on infrastructure nodes, that are exchanging knowledge with one another about said infrastructure. This information could be the software components running on an infrastructure node, computing capacities, and network configurations such as firewall settings. Each agent is only be able to talk with neighbouring agents, as will be described in Subsection \ref{ssec:experiments}.

By exchanging this knowledge each agent only has to maintain a small portion of the complete network, decreasing the problem domain for which it has to think. With this knowledge, an agent can then create an \emph{attack graph} with the use of predefined \emph{risk rules}. These risk rules are based on the knowledge we have from the CVE database. The attack graph then indicates whether or not the system, as known by the agents exchanged knowledge, has any security risks.


% The proposed method of doing this is:

% 1. to have neighbouring agents share information within the network, and keep track of a local knowledge-base.
% 2. have agents calculate an attack graph of its knowledge-base, and apply a set of predefined risk-rules to it. The output of this step is a set of risks with a probability score indicating the probability of an attack happening to a critical component in the network.
% 3. have an agent auction of the highest risk to neighbouring agents. The neighbouring agents receive the attack graph and the calculated risk. They merge the received attack graph with their own knowledge-base.
% 4. The nodes that participate in the auction will use this newly merged attack graph to apply several adoption patterns and propose a mitigation strategy to the auctioneer.
% 5. The adaptation strategy will be selected by the initial agent and the strategy will be applied to the network. 
% 6. This new information will be shared to neighbouring nodes, starting the cycle anew.

The proposed protocol consists of several steps. Firstly, neighbouring agents share information within the network and maintain a local knowledge base. This knowledge base contains information on the software components and other attributes the neighbouring nodes have. Throughout the thesis we introduce a variable that determine the depth to which knowledge is shared in this phase. 

Secondly, agents should use their newly acquired knowledge of their local network with a set of predefined risk-rules to create an Attack Graph. This attack graph contains all nodes and software components in the knowledge base, where the edges are determined by the risk-rules. A rule defines the relation from node-to-node, node-to-software, or software-to-software. These relations are directional and make up a graph through which an attacker could reach a critical piece of software. This Attack Graph is then used to calculate the probability of an attack for each software component. 

An agent selects a risk it wants to mitigate and initiates an auction to neighbouring agents, in which it acts as both the Consignor and the Auctioneer (in auction jargon).  
\question{I don't think it makes sense to sketch the entire idea from the Concept, as this is just the proposal for the rest of the research.}
The neighbouring nodes can then \emph{bid} on the risk in the form of mitigation proposals. These mitigation proposals are created from a set of predefined adaptation patterns. The auctioning agent selects a bid that results in the best reduction of the risk. We note that other strategies could also be considered for selecting the best bid, for example, strategies that take costs and performance into account.

The last step is for the winning agent to apply the changes to its properties, and therefore decrease the overall risk of the network. Neighbouring agents are then notified of these changes, updating their local knowledge bases. This event can potentially trigger the whole flow again, making the network continuously attempt to reduce the overall risk.